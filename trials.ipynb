{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"/mnt/c/Users/Work/Downloads/yolov5-master/yolov5-master/data/sample_vechile_det_dataset/train/images/17e5b483-7482-4977-919f-e9704a3f5cd0.jpg\")\n",
    "image_height, image_width = img.shape[:2]\n",
    "labels = np.array([[0, 0.50716, 0.49336, 0.93099, 0.96132]])\n",
    "segments = [\n",
    "    np.array(\n",
    "       [[    0.97266,     0.51617],\n",
    "       [    0.94922,     0.46478],\n",
    "       [    0.94748,     0.37182],\n",
    "       [    0.91797,     0.33372],\n",
    "       [      0.898,      0.2448],\n",
    "       [    0.87804,     0.19861],\n",
    "       [    0.81207,     0.13453],\n",
    "       [    0.67925,     0.10797],\n",
    "       [     0.7079,    0.012702],\n",
    "       [    0.67708,    0.093534],\n",
    "       [    0.65842,     0.11028],\n",
    "       [    0.41971,     0.10624],\n",
    "       [    0.32118,     0.11547],\n",
    "       [     0.2296,     0.14319],\n",
    "       [    0.19097,     0.17552],\n",
    "       [    0.14236,     0.24018],\n",
    "       [    0.11415,     0.29388],\n",
    "       [   0.099826,     0.28176],\n",
    "       [   0.062934,     0.28637],\n",
    "       [   0.055556,     0.29677],\n",
    "       [   0.057292,     0.33025],\n",
    "       [   0.049045,     0.33718],\n",
    "       [   0.041667,     0.37125],\n",
    "       [   0.045139,     0.44169],\n",
    "       [   0.072917,     0.55196],\n",
    "       [    0.08724,     0.58083],\n",
    "       [     0.1224,     0.58545],\n",
    "       [    0.15321,     0.55601],\n",
    "       [    0.42144,     0.73441],\n",
    "       [    0.42708,     0.81236],\n",
    "       [    0.45139,     0.88106],\n",
    "       [    0.49306,      0.9463],\n",
    "       [    0.54688,     0.97402],\n",
    "       [    0.59679,     0.96016],\n",
    "       [    0.62109,      0.9336],\n",
    "       [    0.63715,      0.8955],\n",
    "       [    0.69965,     0.90012],\n",
    "       [     0.7322,      0.8903],\n",
    "       [    0.78733,     0.85393],\n",
    "       [    0.87413,     0.77021],\n",
    "       [    0.93359,     0.68764],\n",
    "       [    0.97092,      0.5485]]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69881440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(img[:,:,::-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imantics import Polygons, Mask\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "class PreAlbumentations:\n",
    "    ## ONLY SUPPORT ONE OBJECT PER IMAGE FOR NOW\n",
    "    \n",
    "    # YOLOv5 Albumentations class (optional, only used if package is installed)\n",
    "    def __init__(self, margin=0.1):\n",
    "        self.transform = None\n",
    "        # prefix = colorstr('pre load albumentations: ')\n",
    "        try:\n",
    "            import albumentations as A\n",
    "            # check_version(A.__version__, '1.0.3', hard=True)  # version requirement\n",
    "            \n",
    "            # define margin for partial car\n",
    "            self.margin = margin\n",
    "            \n",
    "            # define transforms for partial visible objects\n",
    "            self.transforms_partial = A.Compose(\n",
    "                [\n",
    "                    A.RandomResizedCrop(height=350, width=350, scale=(0.8, 1.0), ratio=(0.9, 1.11), p=1.0),\n",
    "                ], \n",
    "                bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])\n",
    "            )\n",
    "            \n",
    "            # define transforms for completely visible object\n",
    "            self.transforms_commplete = A.Compose(\n",
    "                [\n",
    "                    A.RandomResizedCrop(height=350, width=350, scale=(0.8, 1.0), ratio=(0.9, 1.11), p=1.0),\n",
    "                ], \n",
    "                bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])\n",
    "            )\n",
    "\n",
    "            # LOGGER.info(prefix + ', '.join(f'{x}'.replace('always_apply=False, ', '') for x in T if x.p))\n",
    "        except ImportError:  # package not installed, skip\n",
    "            pass\n",
    "        # except Exception as e:\n",
    "            #LOGGER.info(f'{prefix}{e}')\n",
    "\n",
    "    def __call__(self, im, labels, segments, probability_partial=0.3, probability_complete=0.5):\n",
    "        if len(segments) > 1 or labels.shape[0] > 1:\n",
    "            raise ValueError(\"multiple object per image are not supported yet\")\n",
    "        \n",
    "        # get image height and width\n",
    "        image_height, image_width = im.shape[:2]\n",
    "        \n",
    "        # check if image is partial or full\n",
    "        # xi1, xi2, yi1, yi2 = self.margin, (1-self.margin), self.margin, (1-self.margin)\n",
    "        # xb1, xb2, yb1, yb2 = xc-(w/2), w+xc-(w/2), yc-(h/2), h+yc-(h/2)\n",
    "        \n",
    "        # get bbox co-ordinates\n",
    "        xc, yc, w, h = labels[0, 1:]\n",
    "        \n",
    "        partial_object = False\n",
    "        if xc-w/2 < self.margin and \\\n",
    "            w+xc-w/2 > (1-self.margin) and \\\n",
    "            yc-h/2 < self.margin and \\\n",
    "            h+yc-h/2 > (1-self.margin):   \n",
    "            partial_object = True\n",
    "        \n",
    "        print(partial_object)\n",
    "        \n",
    "        \n",
    "        # convert segments to mask\n",
    "        segments_ = []\n",
    "        for segment_ in segments:\n",
    "            segment_[:, 0] *= image_width\n",
    "            segment_[:, 1] *= image_height\n",
    "            segments_.append(segment_)\n",
    "        \n",
    "        # apply augmentation for partial object\n",
    "        if self.transforms_partial and random.random() < probability_partial and partial_object == True:\n",
    "             # create mask\n",
    "            mask = Polygons(segments_).mask(width=image_width, height=image_height)\n",
    "            \n",
    "            new = self.transforms_partial(image=im, bboxes=labels[:, 1:], class_labels=labels[:, 0], mask=mask.array)\n",
    "            new_im, new_labels = new['image'], np.array([[c, *b] for c, b in zip(new['class_labels'], new['bboxes'])])\n",
    "            new_segments = []\n",
    "            for new_segment in Mask(mask.array).polygons().points:\n",
    "                new_segment = new_segment.astype(np.float64)\n",
    "                new_segment[:, 0] /= image_width\n",
    "                new_segment[:, 1] /= image_height\n",
    "                new_segments.append(new_segment)\n",
    "            return new_im, new_labels, new_segments\n",
    "            \n",
    "        # apply augmentation for complete object\n",
    "        if self.transforms_commplete and random.random() < probability_complete and partial_object == False:\n",
    "            # create mask\n",
    "            mask = Polygons(segments_).mask(width=image_width, height=image_height)\n",
    "            new = self.transforms_commplete(image=im, bboxes=labels[:, 1:], class_labels=labels[:, 0], mask=mask.array)\n",
    "            new_im, new_labels = new['image'], np.array([[c, *b] for c, b in zip(new['class_labels'], new['bboxes'])])\n",
    "            new_segments = []\n",
    "            for new_segment in Mask(mask.array).polygons().points:\n",
    "                new_segment = new_segment.astype(np.float64)\n",
    "                new_segment[:, 0] /= image_width\n",
    "                new_segment[:, 1] /= image_height\n",
    "                new_segments.append(new_segment)\n",
    "            return new_im, new_labels, new_segments\n",
    "        \n",
    "        return im, labels, segments\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PreAlbumentations(margin=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = a(im=img, labels=labels, segments=segments, probability_partial=1.0, probability_complete=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_, labels_, mask_ = op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ = []\n",
    "for segment_ in segments:\n",
    "    segment_[:, 0] *= image_width\n",
    "    segment_[:, 1] *= image_height\n",
    "    segments_.append(segment_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Polygons(segments_).mask(width=image_width, height=image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_segments = []\n",
    "for mask_ in mask.array:\n",
    "    new_points = []\n",
    "    for new_point in Mask(mask.array).polygons().points:\n",
    "        new_point = new_point.astype(np.float64)\n",
    "        new_point[:, 0] /= image_width\n",
    "        new_point[:, 1] /= image_height\n",
    "        new_points.append(new_point)\n",
    "\n",
    "    new_segments.append(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_segments = []\n",
    "for new_segment in Mask(mask.array).polygons().points:\n",
    "    new_segment = new_segment.astype(np.float64)\n",
    "    new_segment[:, 0] /= image_width\n",
    "    new_segment[:, 1] /= image_height\n",
    "    new_segments.append(new_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7847c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_img = cv2.polylines(img, Mask(mask.array).polygons().points, True, (255, 0, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.imshow(drawn_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask(m.array).polygons().points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca199d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk",
   "language": "python",
   "name": "sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
